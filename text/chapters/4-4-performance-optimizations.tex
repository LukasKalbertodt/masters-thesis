\section{Performance Optimizations}

As execution speed is an important goal of \code{lox}, several critical parts of the library were analyzed and optimized to improve performance.
This chapter gives an overview of some of the optimization work that went into this library.

Writing idiomatic Rust code usually already makes sure that the compiled code performs reasonably well, meaning that correctness can be the programmer's main focus when initially writing the code.
To improve speed further, several approaches were used.
For one, a couple of benchmarks comparing \code{lox} to OpenMesh in different situations were created and executed regularly, providing a good baseline.
The programs \emph{perf}\footnote{Performance analyzer for Linux} and Intel$^\text{\tiny ®}$~VTune$^\text{\tiny ™}$~Amplifier\footnote{Website: \url{https://software.intel.com/en-us/vtune}} were used for profiling, i.\,e., to gather different information about a program's runtime behavior.
To inspect generated machine code, the tools Cutter\footnote{Website: \url{https://github.com/radareorg/cutter}} and Godbolt Compiler Explorer\footnote{Website: \url{https://godbolt.org/}} were used.

By profiling different workloads and inspecting the machine code, many performance problems and hotspots were identified across the code base.
Generally, those problems were fixed by rewriting small parts of the code or providing hints to the compiler.
In some cases, the optimizer did not inline tiny functions.
This could be fixed by adding the \code{#[inline(always)]} attribute to those functions, often resulting in a measurable increase in performance.
Important functions that are called very rarely (e.\,g., functions constructing an error object) are instead annotated with \code{#[inline(never)]} and \code{#[cold]}, improving code generation for callers of these functions.

Before any code was changed, at least one benchmark executing that part of the code was written.
That way, the performance impact of a change could always be measured directly.
Changes that would not result in a measurable improvement (or even in decreased performance) would be reverted.

\vspace{-1mm}
\subsubsection*{IO Optimizations}

Most IO operations can fail for several reasons: the operating system might raise an error when interacting with the file system, the parser could detect a malformed input file, sinks or sources can raise errors about incompatible types, and more.
As a consequence, many functions in \code{lox::io} return \code{Result<_, Error>} where \code{Error} is the error type defined in the IO module.
This error type was an enum listing all potential error cases, with some variants storing several fields to describe the error.
Over time, the size of this type grew to 56 bytes.

This is a problem as the return type of many functions would have a significant size, increasing the size of many stack frames.
Functions that were not inlined required a fairly long function prologue and epilogue to prepare this stack data.
To solve this problem, \code{Error} was renamed to \code{ErrorKind} and a new type \code{Error} was defined with a single field of type \code{Box<ErrorKind>}.
In short: the actual error data is now heap allocated and \code{Error} itself is only 8 bytes large.
Additionally, due to null pointer optimization, \code{Result<(), Error>} (often used as return type) is also only 8 bytes in size, meaning it can be returned from functions in a single CPU register, further improving speed.
This layout change resulted in performance improvements for most IO operations between 10\% and 30\%.

Reading \textsc{Ply} files proved particularly challenging as the format supports dynamic lists and a dynamic type system with ten numeric types.
The header of a \textsc{Ply} file defines a list of elements, each defining a list of properties which in turn can either be a list or a scalar.
List elements and scalar values can be one of ten numeric types.
The list property's length is not specified in the header, can vary with each element and is stored next to the list data.
This is problematic as the reader needs to read one property at a time instead of being able to consume a lot of data at once.
Additionally, to read the correct number of bytes for a property, the property's type has to be checked, introducing many branches into the hot inner loop.

To somewhat circumvent the problem, a function pointer was prepared for each property and element.
While this introduces a number of dynamic calls in the hot loop, a lot of checks can be done before reading body data, overall improving reading performance.
The best solution would probably be to parse the file header and then generate specialized machine code for reading body data.
While this could probably improve performance by a large factor, this solution was considered too elaborate for this thesis.


\vspace{-1mm}
\subsubsection*{Data Structure Optimizations}

The main micro-optimization improving performance of data structure operations was related to bound checking.
To guarantee memory safety, Rust performs bound checks whenever array-like structures are indexed.
These checks can usually be removed by the optimizer and therefore are not a big problem.
However, in the context of \code{lox}'s data structures, the optimizer was not able to remove bounds checks most of the time, meaning that a significant runtime overhead was caused by those checks.

Bound checks can be manually removed by using the method \code{get_unchecked}.
This function is marked as \code{unsafe}, meaning that calling it requires an \code{unsafe} block.
This was used for all internal indices, while indices passed in by the user were still checked once.
To improve robustness of this solution, Rust's strong type system was used to distinguish between indices that were proven to be valid and indices that might be invalid.
The library \code{stable-vec} -- offering the underlying dynamic array data structure -- was also optimized to remove unnecessary bound checks.
These optimizations improved overall performance by roughly 20\%.

Another important optimization is based on an additional invariant held by the half edge mesh and directed edge mesh.
Chapter~2 states that these data structures store one arbitrary outgoing half edge per vertex.
The implementations in \code{lox} make sure that if a vertex is a boundary vertex, the half edge stored in the \code{outgoing} field is a boundary half edge as well.
This requires only a bit more work in methods mutating the mesh, but means that checking whether a vertex lies on the boundary is a lot faster, as only one adjacent half edge has to be checked.
This optimization is also used in OpenMesh.
